{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c98372b",
   "metadata": {},
   "source": [
    "# Tema 3: Evaluación de algortimos de clasificación\n",
    "## Cuaderno de ejercicios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f4bf1",
   "metadata": {},
   "source": [
    "# **Ejercicio 1**\n",
    "\n",
    "Supongamos que hemos utilizado un clasificador, por ejemplo, Naive Bayes, para clasificar documentos con respecto al sentimiento. Las clases son Pos (positivo), Neg (negativo) y Neu (neutro). Probamos nuestro clasificador en 10 documentos para los que conocemos su _gold standar_ (clase real). La prueba tiene los siguientes resultados:\n",
    "\n",
    "| Documento | Clase Real | Clase predicha |\n",
    "| ------------- | ------------- | ------------- |\n",
    "| d1  | Pos  | Pos |\n",
    "| d2  | Pos  | Pos |\n",
    "| d3  | Pos  | Pos |\n",
    "| d4  | Pos  | Neu |\n",
    "| d5  | Neg  | Neg |\n",
    "| d6  | Neg  | Neu |\n",
    "| d7  | Neg  | Neg |\n",
    "| d8  | Neu  | Pos |\n",
    "| d9  | Neu  | Neu |\n",
    "| d10  | Neu  | Neu |\n",
    "\n",
    "Calcular: precision, recall, accuracy y F1 para estos resultados de clasificación para las tres clases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cb271",
   "metadata": {},
   "source": [
    "**Ejercicio 2**\n",
    "\n",
    "Se evaluó un clasificador binario utilizando un conjunto de 1000 ejemplos de prueba (test) en los que el 50 % de todos los ejemplos son negativos. El clasificador tiene 60 % de sensitivity y 70 % de accuracy. Escribe la matriz de confusión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d48473b",
   "metadata": {},
   "source": [
    "**Ejercicio 3**\n",
    "\n",
    "Utilizando la matriz de confusión creada en el ejercicio anterior, calcula la precisión del clasificador, la medida F1 y\n",
    "especificidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2287950c",
   "metadata": {},
   "source": [
    "## **Resolusion ejercicio 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c7f3bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc8b332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precsion_Pos = 0.75\n",
      "precsion_Neg = 1.0\n",
      "precsion_Neu = 0.5 \n",
      "\n",
      "recall_Pos = 0.75\n",
      "recall_Neg = 0.6666666666666666\n",
      "recall_Neu = 0.6666666666666666 \n",
      "\n",
      "f_measure_pos = 0.75\n",
      "f_measure_neg = 0.8\n",
      "f_measure_neu = 0.5714285714285715 \n",
      "\n",
      "accuracy_pos = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# precision = tp /(tp + fp)  --> recall = tp/(tp+fn)\n",
    "# tp_Pos = d1(Pos - Pos) + d2 + d3\n",
    "# tn_pos = d8\n",
    "# tp_neg = d5 + d7\n",
    "# tp_neu = d9 + d10\n",
    "# --------------------falso positivo (predicho espera pos, pero real no)\n",
    "# fp_pos = d8\n",
    "# fp_neg = 0\n",
    "# fp_neu = d4 + d6\n",
    "# ------------------ falso negativo (real espera pos, pero predicho no)\n",
    "# fn_pos = d4\n",
    "# fn_neg = d6\n",
    "# fn_neu = d8\n",
    "precsion1_pos = 3/(3+1)\n",
    "precsion1_neg = 2/(2+0)\n",
    "precsion1_neu = 2/(2+2)\n",
    "\n",
    "recall1_pos = 3/(3+1)\n",
    "recall1_neg = 2/(2+1)\n",
    "recall1_neu = 2/(2+1)\n",
    "print(\"precsion_Pos =\",precsion1_pos)\n",
    "print(\"precsion_Neg =\",precsion1_neg)\n",
    "print(\"precsion_Neu =\",precsion1_neu,\"\\n\")\n",
    "\n",
    "print(\"recall_Pos =\",recall1_pos)\n",
    "print(\"recall_Neg =\",recall1_neg)\n",
    "print(\"recall_Neu =\",recall1_neu,\"\\n\")\n",
    "\n",
    "f_measure1_pos = (2*(precsion1_pos*recall1_pos))/(precsion1_pos+recall1_pos)\n",
    "f_measure1_neg = (2*(precsion1_neg*recall1_neg))/(precsion1_neg+recall1_neg)\n",
    "f_measure1_neu = (2*(precsion1_neu*recall1_neu))/(precsion1_neu+recall1_neu)\n",
    "\n",
    "print(\"f_measure_pos =\",f_measure1_pos)\n",
    "print(\"f_measure_neg =\",f_measure1_neg)\n",
    "print(\"f_measure_neu =\",f_measure1_neu,\"\\n\")\n",
    "\n",
    "accuracy1_pos = (3+1)/(3+1+1+1) #calculo a mano\n",
    "print(\"accuracy_pos =\",accuracy1_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0eafc503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_pos 0.6\n",
      "Accuracy_neg 0.6666666666666666\n",
      "Accuracy_neu 0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "#Solve con librerias:\n",
    "import pandas as pd\n",
    "\n",
    "datos_pos = [[1,'Pos','Pos'],\n",
    "        [2,'Pos','Pos'],\n",
    "        [3,'Pos','Pos'],\n",
    "        [4,'Pos','Neu'],\n",
    "        [5,'Neu','Pos']]\n",
    "\n",
    "datos_neg = [[1,'Neg','Neg'],\n",
    "        [2,'Neg','Neu'],\n",
    "        [3,'Neg','Neg']]\n",
    "\n",
    "datos_neu = [[8,'Neu','Pos'],\n",
    "        [9,'Neu','Neu'],\n",
    "        [4,'Pos','Neu'],\n",
    "        [6,'Neg','Neu'],\n",
    "        [8,'Neu','Pos'],\n",
    "        [9,'Neu','Neu'],\n",
    "        [10,'Neu','Neu']]\n",
    "# el identificador de documento realmente no haría falta\n",
    "\n",
    "# definimos los nombres de las columnas\n",
    "columnas = ['id', 'Real', 'Predicted'] \n",
    "\n",
    "df = pd.DataFrame(datos_pos, columns=columnas)\n",
    "df_neg = pd.DataFrame(datos_neg, columns=columnas)\n",
    "df_neu = pd.DataFrame(datos_neu, columns=columnas)\n",
    "\n",
    "#print(df)   \n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "accuracy_val_pos = accuracy_score(df['Real'], df['Predicted'])\n",
    "print(\"Accuracy_pos\",accuracy_val_pos)   \n",
    "accuracy_val_neg = accuracy_score(df_neg['Real'], df_neg['Predicted'])\n",
    "print(\"Accuracy_neg\",accuracy_val_neg)   \n",
    "accuracy_val_neu = accuracy_score(df_neu['Real'], df_neu['Predicted'])\n",
    "print(\"Accuracy_neu\",accuracy_val_neu)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d245d",
   "metadata": {},
   "source": [
    "### Resolucion ejercicio 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab832f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp = 300.0\n",
      "tn = 400.0\n",
      "fn = 200.0\n",
      "fp = 100.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#datos de inicio\n",
    "Positivos = 500\n",
    "negativos = 500\n",
    "total = 1000\n",
    "sensitivity = 0.6 # %60\n",
    "accuracy = 0.7 #%70\n",
    "\n",
    "# recall = tp / tp + fn -> tp = recall*(tp + fn)\n",
    "# sensitivity = tp / (tp + fn)  -> tp = sensitivity * (tp+fn)\n",
    "# accuracy = (tp + tn)/(tp + fp + tn + fn) -> accurancy*(tp + fp + tn + fn) = tp + tn -> tn = accurancy*(tp + fp + tn + fn) -tp\n",
    "# total_positivo = verdadero_positivo + falso negativo -> (TP + FN)\n",
    "# total_negativo = falso positivo + verdadero_negativo -> (FP + TN)\n",
    "tp = 0.6*500\n",
    "tn = accuracy*total - tp \n",
    "# fn = all - tp\n",
    "# fp = all - tn\n",
    "fn = Positivos - tp\n",
    "fp = negativos - tn\n",
    "print(\"tp =\",tp)\n",
    "print(\"tn =\",tn)\n",
    "print(\"fn =\",fn)\n",
    "print(\"fp =\",fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6521c3",
   "metadata": {},
   "source": [
    "### calculo ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bec8685a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "presicion = 0.75\n",
      "f1 = 0.5\n",
      "specificity = 0.8\n"
     ]
    }
   ],
   "source": [
    "# presicion = tp / tp + fp\n",
    "# f1 = 2*tp / 2*(tp + fp + fn)\n",
    "# specificity = tn / (tn + fp)\n",
    "presicion = tp / (tp +fp)\n",
    "f1 = 2*(tp) / (2*(tp + fp + fn))\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "print(\"presicion =\", presicion)\n",
    "print(\"f1 =\", f1)\n",
    "print(\"specificity =\", specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598d939",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
